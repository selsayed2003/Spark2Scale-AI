import json
import os
import time
from langchain_core.messages import HumanMessage
import requests
from datetime import datetime
from dotenv import load_dotenv
import builtwith
from urllib.parse import urlparse


# LangChain & AI Imports
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_ollama import ChatOllama
from langchain_google_genai.chat_models import ChatGoogleGenerativeAIError
from google.api_core.exceptions import ResourceExhausted

# Resilience
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# Local Imports (Assumed to exist based on your code)
from prompts import (
    CONTRADICTION_MARKET_PROMPT_TEMPLATE,
    CONTRADICTION_PRODUCT_PROMPT_TEMPLATE,
    CONTRADICTION_TEAM_PROMPT_TEMPLATE,
    VALUATION_RISK_MARKET_PROMPT_TEMPLATE, 
    VALUATION_RISK_PROBLEM_PROMPT_TEMPLATE,
    VALUATION_RISK_PRODUCT_PROMPT_TEMPLATE, 
    VALUATION_RISK_TEAM_PROMPT_TEMPLATE, 
    TEAM_SCORING_AGENT_PROMPT, 
    CONTRADICTION_PROBLEM_PROMPT_TEMPLATE, 
    PROBLEM_SCORING_AGENT_PROMPT,
    VISUAL_VERIFICATION_PROMPT,
    PRODUCT_SCORING_AGENT_PROMPT,
    MARKET_SCORING_AGENT_PROMPT
)
from helpers import (
    extract_problem_data, 
    extract_team_data, 
    load_schema,
    extract_product_data,
    extract_market_data, 
    capture_screenshot)

# Load Environment Variables
load_dotenv()

# --- CONFIGURATION ---
RETRY_CONFIG = {
    "wait": wait_exponential(multiplier=2, min=10, max=120),
    "stop": stop_after_attempt(20),
    "retry": retry_if_exception_type((ResourceExhausted, ChatGoogleGenerativeAIError))
}

# --- TOOLS & AGENTS ---

def check_missing_fields(data, parent_path=""):
    '''Recursively checks for empty values in a nested JSON object to identify incomplete data.
    
    Params:
        data - The dictionary or list to be scanned for missing values.
        parent_path - A string tracking the nested key hierarchy for error reporting (defaults to empty string).
        
    Returns:
        list - A list of strings, each detailing the path of a missing or empty field.
    '''
    missing_errors = []

    if isinstance(data, dict):
        for key, value in data.items():
            current_path = f"{parent_path}.{key}" if parent_path else key

            if value is None or value == "" or value == [] or value == {}:
                missing_errors.append(f"Missing Value: Field '{current_path}' is empty.")
            else:
                missing_errors.extend(check_missing_fields(value, current_path))

    elif isinstance(data, list):
        for index, item in enumerate(data):
            item_path = f"{parent_path}[{index}]"
            missing_errors.extend(check_missing_fields(item, item_path))

    return missing_errors

@retry(**RETRY_CONFIG)
def contradiction_check(data: dict, agent_prompt: str) -> str:
    '''Uses Google Gemini Flash to detect logical contradictions within the provided startup data.
    
    Params:
        data - Dictionary containing the startup information to be analyzed.
        agent_prompt - The specific prompt template string used to instruct the LLM.
        
    Returns:
        str - A text report generated by the AI detailing found contradictions or an error message.
        
    Raises:
        ChatGoogleGenerativeAIError - Raised when the AI model fails to process the request.
    '''
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0, 
        google_api_key=os.environ.get("GEMINI_API_KEY") 
    )

    prompt = PromptTemplate.from_template(agent_prompt)
    
    try:
        chain = prompt | llm_flash | StrOutputParser()
        result = chain.invoke({
            "current_date": datetime.now().strftime("%Y-%m-%d"),
            "json_data": json.dumps(data, indent=2) 
        })
        return result
    except Exception as e:
        return f"Error performing Contradiction Check: {str(e)}"

@retry(**RETRY_CONFIG)
def team_risk_check(data: dict, agent_prompt: str) -> str:
    '''Identifies specific investment risks by analyzing the startup data through an AI agent.
    
    Params:
        data - Dictionary containing the startup information to be evaluated.
        agent_prompt - The prompt template directing the LLM to look for specific risk factors.
        
    Returns:
        str - A detailed risk assessment report in string format.
        
    Raises:
        ResourceExhausted - Raised when API quota limits are exceeded.
    '''
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0, 
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    prompt = PromptTemplate.from_template(agent_prompt)

    try:
        chain = prompt | llm_flash | StrOutputParser()
        result = chain.invoke({
            "json_data": json.dumps(data, indent=2)
        })
        return result
    except Exception as e:
        return f"Error performing Risk Check: {str(e)}"
    
@retry(**RETRY_CONFIG)
def loaded_risk_check_with_search(problem_data: dict, search_results: dict, agent_prompt: str) -> str:
    '''Analyzes problem statement risks by cross-referencing internal claims with external search results.
    
    Params:
        problem_data - Dictionary containing the startup's internal problem definition.
        search_results - Dictionary containing external evidence gathered via web search.
        
    Returns:
        str - A formatted report (Markdown) highlighting risks or system errors.
    '''
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    prompt = PromptTemplate.from_template(agent_prompt)

    try:
        chain = prompt | llm_flash | StrOutputParser()
        result = chain.invoke({
            "internal_json": json.dumps(problem_data, indent=2),
            "external_search_json": json.dumps(search_results, indent=2)
        })
        return result
    except Exception as e:
        return f"## Problem Risks\n* **System Error**: Could not perform risk check.\n  * *Evidence:* {str(e)}"


@retry(**RETRY_CONFIG)
def verify_problem_claims(problem_statement: str, target_audience: str) -> dict:
    '''Performs a targeted web search using Serper API to verify the validity of a startup's problem claim.
    
    Params:
        problem_statement - A string describing the core problem the startup intends to solve.
        target_audience - A string describing the specific user persona or role affected.
        
    Returns:
        dict - A dictionary containing generated search queries and the resulting organic search snippets.
        
    Raises:
        requests.exceptions.RequestException - Raised if the web search API call fails.
    '''
    api_key = os.environ.get("SERPER_API_KEY")
    google_api_key = os.environ.get("GEMINI_API_KEY")
    
    if not api_key:
        return {"error": "Missing SERPER_API_KEY."}

    # STEP 1: GENERATE QUERIES
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=google_api_key)
    
    query_gen_prompt = f"""
    You are a Search Expert. Convert this startup problem into 3 specific Google search queries.
    
    Target Audience: {target_audience}
    Problem: {problem_statement}
    
    Output JSON ONLY:
    {{
        "pain_query": "Find forum discussions (Reddit/Quora) using specific keywords from the problem.",
        "symptom_query": "Find discussions describing the FEELING of the problem using SIMPLE, NON-TECHNICAL words.",
        "solution_query": "Find existing competitors or software solutions."
    }}
    """
    
    try:
        query_response = llm.invoke(query_gen_prompt)
        clean_json = query_response.content.replace("```json", "").replace("```", "").strip()
        queries = json.loads(clean_json)
        
        pain_q = queries.get("pain_query", f"{problem_statement} reddit")
        symptom_q = queries.get("symptom_query", f"{target_audience} struggle reddit")
        sol_q = queries.get("solution_query", f"solution for {problem_statement}")
    except Exception:
        pain_q = f"{target_audience} {problem_statement} reddit"
        symptom_q = f"{target_audience} struggle help forum"
        sol_q = f"best solution for {problem_statement}"

    # STEP 2: EXECUTE SEARCH
    url = "https://google.serper.dev/search"
    headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}
    
    results_report = {
        "generated_queries": { 
            "technical_pain": pain_q, 
            "human_symptom": symptom_q, 
            "competitor": sol_q 
        }, 
        "pain_validation_search": [], 
        "competitor_search": []
    }

    def run_search(query):
        try:
            resp = requests.post(url, headers=headers, data=json.dumps({"q": query, "num": 4}))
            if resp.status_code == 200:
                return [
                    {"title": r.get("title"), "link": r.get("link"), "snippet": r.get("snippet")}
                    for r in resp.json().get("organic", [])
                ]
        except: 
            return []
        return []

    results_report["pain_validation_search"].extend(run_search(pain_q))
    results_report["pain_validation_search"].extend(run_search(symptom_q))
    results_report["competitor_search"] = run_search(sol_q)

    return results_report

@retry(**RETRY_CONFIG)
def tech_stack_detective(url: str):
    """
    Identifies if a site is No-Code (Canva, Bubble, Webflow) or Custom Code.
    Now includes a 'Domain Check' to catch subdomains like 'my.canva.site'.
    """
    print(f"üõ†Ô∏è Analyzing tech stack of {url}...")
    
    # --- 1. SMART DOMAIN CHECK (Fastest Method) ---
    # Many no-code sites use specific subdomains. Check this first.
    domain = urlparse(url).netloc.lower()
    
    known_subdomains = {
        "canva.site": "Canva",
        "wixsite.com": "Wix",
        "bubbleapps.io": "Bubble",
        "framer.website": "Framer",
        "myshopify.com": "Shopify",
        "wordpress.com": "WordPress",
        "webflow.io": "Webflow",
        "softr.app": "Softr",
        "glideapp.io": "Glide",
        "carrd.co": "Carrd"
    }
    
    for sub, platform in known_subdomains.items():
        if sub in domain:
            return {
                "technologies_found": [platform, "Subdomain Identified"],
                "is_no_code": True,
                "verdict": f"No-Code ({platform})",
                "status": "Success",
                "evidence": f"URL contains '{sub}'"
            }

    # --- 2. DEEP TECH SCAN (If domain check passed) ---
    try:
        tech_data = builtwith.parse(url)
        
        detected_tech = []
        is_no_code = False
        no_code_platform = None
        
        # Flatten the dictionary
        for category, items in tech_data.items():
            for item in items:
                detected_tech.append(item)
                
        # Expanded No-Code List
        no_code_signals = [
            "Bubble", "Webflow", "Wix", "Squarespace", 
            "WordPress", "Framer", "Shopify", "Weebly", "Carrd",
            "Canva", "Tilda", "Kajabi", "Teachable", "Thinkific", 
            "Ghost", "Substack", "Gumroad", "Notion"
        ]
        
        for tech in detected_tech:
            # Check if any known no-code tool is in the detected list
            for signal in no_code_signals:
                if signal.lower() in tech.lower():
                    is_no_code = True
                    no_code_platform = signal
                    break
            if is_no_code:
                break

        # 3. Formulate Verdict
        if is_no_code:
            verdict = f"Likely No-Code ({no_code_platform})"
        else:
            verdict = "Custom / Standard Stack"
        
        return {
            "technologies_found": detected_tech,
            "is_no_code": is_no_code,
            "verdict": verdict,
            "status": "Success",
            "evidence": "Tech Stack Fingerprint"
        }
        
    except Exception as e:
        return {
            "error": f"Tech detection failed: {str(e)}", 
            "status": "Failed"
        }

@retry(**RETRY_CONFIG)
def analyze_visuals_with_langchain(company_name, website_url, prompt_template):
    """
    Captures a screenshot and sends it + the text prompt to Gemini Vision.
    """
    
    # 1. Capture Screenshot (Using the capture function we defined earlier)
    # Ensure capture_screenshot returns a dictionary with "image_b64"
    if not website_url:
        return "## Visual Risks\n* **Website Offline**: No URL provided."
    capture_result = capture_screenshot(website_url)
    
    if "error" in capture_result:
        return f"## Visual Risks\n* **Website Offline**: {capture_result['error']}"

    image_b64 = capture_result["image_b64"]

    # 2. Prepare the Model
    llm_vision = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0,
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    # 3. Format the Text Prompt (Inject variables)
    formatted_prompt_text = prompt_template.format(
        company_name=company_name,
        website_url=website_url
    )

    # 4. Construct the Multimodal Message
    # LangChain expects a list of content parts for Vision models
    message = HumanMessage(
        content=[
            {"type": "text", "text": formatted_prompt_text},
            {"type": "image_url", "image_url": f"data:image/png;base64,{image_b64}"}
        ]
    )

    # 5. Invoke
    try:
        response = llm_vision.invoke([message])
        return response.content
    except Exception as e:
        return f"## Visual Analysis Error\n* **AI Processing Failed**: {str(e)}"
    

def regulation_trend_radar_tool(category: str, location: str):
    """
    Scans for regulatory risks (e.g., Licenses needed) and market trends (Growth/Decline).
    """
    print(f"üì° Scanning Regulations & Trends for: '{category}' in '{location}'...")
    
    url = "https://google.serper.dev/search"
    api_key = os.environ.get("SERPER_API_KEY")
    headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}

    results_data = {}
    
    # Dynamic Year Logic
    current_year = datetime.now().year
    next_year = current_year + 1

    # --- CHECK 1: REGULATIONS ---
    try:
        # e.g., "Fintech regulatory risks compliance laws Egypt"
        reg_query = f"{category} regulatory risks compliance laws {location}"
        payload_reg = json.dumps({"q": reg_query})
        
        resp_reg = requests.post(url, headers=headers, data=payload_reg)
        reg_hits = resp_reg.json().get("organic", [])[:3]
        
        results_data["regulatory_evidence"] = "\n".join(
            [f"- {r['title']}: {r['snippet']}" for r in reg_hits]
        )
    except Exception as e:
        results_data["regulatory_evidence"] = f"Search Failed: {str(e)}"

    # --- CHECK 2: MARKET TRENDS ---
    try:
        # e.g., "Fintech market growth rate outlook 2026 2027 Egypt"
        trend_query = f"{category} market growth rate outlook {current_year} {next_year} {location}"
        payload_trend = json.dumps({"q": trend_query})
        
        resp_trend = requests.post(url, headers=headers, data=payload_trend)
        trend_hits = resp_trend.json().get("organic", [])[:3]
        
        results_data["trend_evidence"] = "\n".join(
            [f"- {r['title']}: {r['snippet']}" for r in trend_hits]
        )
    except Exception as e:
        results_data["trend_evidence"] = f"Search Failed: {str(e)}"

    return {
        "tool": "Regulation_Radar",
        "category": category,
        "location": location,
        "findings": results_data
    }

def tam_sam_verifier_tool(beachhead: str, location: str, claimed_size: str):
    print(f"üìä Verifying Market Size for: '{beachhead}' in '{location}'...")
    
    # Dynamic Date Logic
    current_year = datetime.now().year
    years_str = f"{current_year} {current_year - 1}"
    
    search_query = f"total number of {beachhead} in {location} statistics {years_str}"
    
    # --- MOCK RESPONSE FOR TESTING (If you don't have an API Key) ---
    # Delete this block if you have a real SERPER_API_KEY
    if not os.environ.get("SERPER_API_KEY"):
        return {
            "tool": "TAM_Verifier",
            "status": "Simulated Success",
            "search_query": search_query,
            "evidence": "Found ~2.5 million potential customers matching criteria."
        }
    # ----------------------------------------------------------------

    url = "https://google.serper.dev/search"
    api_key = os.environ.get("SERPER_API_KEY")
    headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps({"q": search_query}))
        results = response.json()
        snippets = [f"- {i['title']}: {i['snippet']}" for i in results.get("organic", [])[:3]]
        
        return {
            "tool": "TAM_Verifier",
            "founder_claim": claimed_size,
            "search_query": search_query,
            "search_evidence": "\n".join(snippets),
            "status": "Success"
        }
    except Exception as e:
        return {"error": str(e)}
    
    
def local_dependency_detective(tech_stack: str, acquisition_channel: str, product_desc: str):
    print("üïµÔ∏è  Running Smart Dependency Detective (Local Llama3)...")
    
    # --- CHANGE 1: USE OLLAMA INSTEAD OF GEMINI ---
    # Llama 3 (8B) is excellent at following JSON instructions.
    # Make sure you ran 'ollama pull llama3' in your terminal first.
    llm = ChatOllama(
        model="gemma3:1b", 
        format="json",  # <--- Crucial: Forces local model to output valid JSON
        temperature=0
    )

    analysis_prompt = """
    You are a Technical Due Diligence Analyst. 
    Analyze this startup for Platform Risks (Sherlocking, ToS Violations, Dependencies).
    
    Context:
    - Product: "{product}"
    - Tech Stack: "{tech}"
    - Acquisition: "{channel}"
    
    Respond ONLY with a JSON object in this format:
    {{
        "risk_level": "High/Medium/Low",
        "red_flags": ["List specific risks..."],
        "search_query_needed": "Search query for recent bans (e.g., 'LinkedIn scraping lawsuits') or 'None'"
    }}
    """
    
    prompt = PromptTemplate(template=analysis_prompt, input_variables=["product", "tech", "channel"])
    chain = prompt | llm | JsonOutputParser()
    
    try:
        # Run Local LLM
        analysis = chain.invoke({
            "product": product_desc,
            "tech": tech_stack,
            "channel": acquisition_channel
        })
        
        # --- STEP 2: VERIFICATION (Same as before) ---
        # The Local LLM identifies the logic (e.g., "This is scraping"), 
        # and we use the API to check if it's currently being banned.
        
        verification_note = ""
        search_query = analysis.get("search_query_needed", "None")
        
        # Only run search if it's a real query (sometimes models hallucinate a query)
        if search_query != "None" and "None" not in search_query and os.environ.get("SERPER_API_KEY"):
            print(f"   -> üîç Verifying risk locally via Search: '{search_query}'...")
            
            url = "https://google.serper.dev/search"
            headers = {'X-API-KEY': os.environ.get("SERPER_API_KEY"), 'Content-Type': 'application/json'}
            resp = requests.post(url, headers=headers, data=json.dumps({"q": search_query}))
            
            if resp.status_code == 200:
                snippets = [r['snippet'] for r in resp.json().get('organic', [])[:2]]
                verification_note = f"\n**Forensic Evidence:** {snippets}"
        
        return {
            "tool": "Dependency_Detective_Local",
            "risk_level": analysis.get("risk_level"),
            "analysis": f"**{analysis.get('risk_level').upper()} RISK**\n" + 
                        "\n".join([f"‚ö†Ô∏è {flag}" for flag in analysis.get("red_flags", [])]) + 
                        verification_note
        }

    except Exception as e:
        return {"tool": "Dependency_Detective_Local", "error": str(e)}
    
def market_risk_agent(market_inputs, tam_result, radar_result, dep_result):
    
    # 1. Setup LLM
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
    
    # 2. Setup Prompt
    prompt = PromptTemplate(
        template=VALUATION_RISK_MARKET_PROMPT_TEMPLATE,
        input_variables=["internal_json", "tam_report", "radar_report", "dependency_report"]
    )
    
    # 3. Create Chain
    chain = prompt | llm | StrOutputParser()
    
    # 4. Run Analysis
    print("üìâ Running Market Risk Analysis...")
    result = chain.invoke({
        "internal_json": json.dumps(market_inputs, indent=2),
        "tam_report": json.dumps(tam_result, indent=2),
        "radar_report": json.dumps(radar_result, indent=2),
        "dependency_report": json.dumps(dep_result, indent=2)
    })
    
    return result
@retry(**RETRY_CONFIG)
def team_scoring_agent(data_package: dict) -> dict:
    '''Synthesizes risk reports, contradiction checks, and missing info to assign a final team investment score.
    
    Params:
        data_package - A dictionary containing 'user_data', 'risk_report', 'contradiction_report', and 'missing_report'.
        
    Returns:
        dict - A JSON-parsed dictionary containing the numerical score and the reasoning.
    '''
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0, 
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    prompt = PromptTemplate.from_template(TEAM_SCORING_AGENT_PROMPT)

    try:
        chain = prompt | llm_flash | JsonOutputParser()
        
        result_dict = chain.invoke({
            "user_json_data": json.dumps(data_package.get("user_data", {}), indent=2),
            "risk_agent_output": str(data_package.get("risk_report", "None")),
            "contradiction_agent_output": str(data_package.get("contradiction_report", "None")),
            "missing_info_output": str(data_package.get("missing_report", "None"))
        })
        return result_dict
    except Exception as e:
        return {"result": f"System Error: {str(e)}"}

@retry(**RETRY_CONFIG)
def problem_scoring_agent(data_package: dict) -> str:
    '''Synthesizes various problem-related reports to assign a final qualitative and quantitative score.
    
    Params:
        data_package - A dictionary containing problem definitions, missing reports, and search validation results.
        
    Returns:
        str - A formatted text block including the score, rubric definition, confidence level, and key evidence.
    '''
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0, 
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    prompt = PromptTemplate.from_template(PROBLEM_SCORING_AGENT_PROMPT)
    chain = prompt | llm_flash | JsonOutputParser()
    
    result_dict = chain.invoke({
        "problem_json": json.dumps(data_package.get("problem_definition", {}), indent=2),
        "missing_report": str(data_package.get("missing_report", "None")),
        "search_json": json.dumps(data_package.get("search_report", {}), indent=2),
        "risk_report": str(data_package.get("risk_report", "None")),
        "contradiction_report": str(data_package.get("contradiction_report", "None"))
    })

    evidence_formatted = "\n".join([f"- {e}" for e in result_dict.get('evidence_used', [])])
    
    final_text = (
        f"{result_dict.get('title', 'Problem Evaluation')}\n"
        f"Score: {result_dict.get('score', 'N/A')} - {result_dict.get('rubric_definition', '')}\n"
        f"Confidence: {result_dict.get('confidence_level', 'Unknown')}\n\n"
        f"Explanation:\n{result_dict.get('explanation', 'No explanation.')}\n\n"
        f"Key Evidence:\n{evidence_formatted}"
    )
    return final_text

@retry(**RETRY_CONFIG)
def product_scoring_agent(data_package: dict) -> str:
    '''Synthesizes product reports to assign a final score (No extra tools required).'''
    
    # 1. Setup LLM
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    # 2. Define Prompt
    prompt = PromptTemplate(
        template=PRODUCT_SCORING_AGENT_PROMPT,
        input_variables=[
            "current_date",
            "internal_data", 
            "contradiction_report", 
            "risk_report", 
            "tech_stack_report", 
            "visual_analysis_report"
        ]
    )
    today_str = datetime.now().strftime("%Y-%m-%d")

    # 3. Execution Chain
    chain = prompt | llm_flash | JsonOutputParser()
    
    try:
        # 4. Invoke (Removed ocean_meter_report)
        result_dict = chain.invoke({
            "current_date": today_str,
            "internal_data": json.dumps(data_package.get("internal_data", {}), indent=2),
            "contradiction_report": str(data_package.get("contradiction_report", "None")),
            "risk_report": str(data_package.get("risk_report", "None")), # LLM reads this to decide Ocean Type
            "tech_stack_report": str(data_package.get("tech_stack_report", "None")),
            "visual_analysis_report": str(data_package.get("visual_analysis_report", "None"))
        })

        # 5. Format Output
        red_flags_list = result_dict.get('red_flags', [])
        formatted_flags = "\n".join([f"üö© {flag}" for flag in red_flags_list]) if red_flags_list else "‚úÖ No critical flags."

        score = result_dict.get('score', 0)
        rubric_map = {
            0: "No Product / Vaporware",
            1: "Me-too Solution",
            2: "Incremental Improvement",
            3: "Clear Value (Pre-Seed Bar)",
            4: "Non-Obvious / 10x (Seed Bar)",
            5: "Breakthrough / Defensible Moat"
        }
        
        final_text = (
            f"üéØ **Product & Solution Evaluation**\n"
            f"**Score:** {score}/5 - {rubric_map.get(score, '')}\n"
            f"**Confidence:** {result_dict.get('confidence_level', 'Unknown')}\n\n"
            
            f"**üåä Ocean Analysis (AI Derived):**\n"
            f"{result_dict.get('ocean_analysis', 'Not analyzed.')}\n\n"
            
            f"**üìù Justification:**\n"
            f"{result_dict.get('justification', 'No justification provided.')}\n\n"
            
            f"**‚ö†Ô∏è Red Flags:**\n"
            f"{formatted_flags}"
        )
        return final_text

    except Exception as e:
        return f"‚ùå Scoring Failed: {str(e)}"
def market_scoring_agent(data_package: dict) -> dict:
    '''
    Synthesizes market reports to assign a final score.
    Returns: JSON Dictionary
    '''
    
    print("‚öñÔ∏è  Running Market Scoring Agent (JSON Output)...")

    # 1. Setup LLM
    llm_flash = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0,
        google_api_key=os.environ.get("GEMINI_API_KEY")
    )

    # 2. Define Prompt
    prompt = PromptTemplate(
        template=MARKET_SCORING_AGENT_PROMPT,
        input_variables=[
            "current_date",
            "internal_data", 
            "contradiction_report", 
            "tam_report", 
            "radar_report", 
            "dependency_report"
        ]
    )
    today_str = datetime.now().strftime("%Y-%m-%d")

    # 3. Execution Chain
    chain = prompt | llm_flash | JsonOutputParser()
    
    try:
        # 4. Invoke
        result_dict = chain.invoke({
            "current_date": today_str,
            "internal_data": json.dumps(data_package.get("internal_data", {}), indent=2),
            "contradiction_report": str(data_package.get("contradiction_report", "None")),
            "tam_report": str(data_package.get("tam_report", "None")),
            "radar_report": str(data_package.get("radar_report", "None")),
            "dependency_report": str(data_package.get("dependency_report", "None"))
        })

        # 5. Enrich with Rubric Definition (Optional but helpful)
        score_str = str(result_dict.get('score', "0")).split("/")[0]
        score_num = int(score_str) if score_str.isdigit() else 0
        
        rubric_map = {
            0: "Market Undefined / Too Small",
            1: "Narrow Market (Limited Upside)",
            2: "Medium Market (Unclear Expansion)",
            3: "Large Market (Pre-Seed Bar)",
            4: "Expanding Market (Seed Bar)",
            5: "Category Creator (Blue Ocean)"
        }
        
        # Add the human-readable rating to the JSON
        result_dict["rubric_rating"] = rubric_map.get(score_num, "Unknown")
        result_dict["score_numeric"] = score_num # Clean integer for math

        return result_dict

    except Exception as e:
        return {"error": "Market Scoring Failed", "details": str(e)}

# --- MAIN EXECUTION PIPELINE ---
if __name__ == "__main__":
    
    # 1. Load Data
    print("üìÇ Loading data from schema.json...")
    input_data = load_schema("schema.json")
    
    if not input_data:
        print("‚ùå Error: Could not load schema.json. Using dummy data.")
        input_data = {"startup_evaluation": {}}
    raw_startup_data = input_data.get("startup_evaluation", input_data)
    
    start_time = time.time()
    
    # Check Missing Fields (Global)
    missing_fields_result = check_missing_fields(input_data)

    # # =========================================================
    # # PHASE 1: TEAM EVALUATION
    # # =========================================================
    # print("\n" + "="*50)
    # print("üë• PHASE 1: TEAM EVALUATION AGENT")
    # print("="*50)
    # team_scope_data = extract_team_data(input_data)

    # # A. Contradiction Check
    # print("\nü§ñ Running Team Contradiction Check...")
    # try:
    #     team_contradiction_result = contradiction_check(team_scope_data, agent_prompt=CONTRADICTION_TEAM_PROMPT_TEMPLATE)
    #     print("   -> Done.")
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Contradiction): {e}")
    #     team_contradiction_result = "Error."

    # # B. Risk Check
    # print("\nüìâ Running Team Risk Check...")
    # try:
    #     team_risk_result = team_risk_check(team_scope_data, agent_prompt=VALUATION_RISK_TEAM_PROMPT_TEMPLATE)
    #     print("   -> Done.")
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Risk): {e}")
    #     team_risk_result = "Error."
    
    # # C. Scoring Agent
    # print("\nüèÜ Running Team Scoring Agent...")
    # try:
    #     team_package = {
    #         "user_data": team_scope_data,
    #         "risk_report": team_risk_result,
    #         "contradiction_report": team_contradiction_result,
    #         "missing_report": missing_fields_result
    #     }
    #     final_team_score = team_scoring_agent(team_package)
    #     print(json.dumps(final_team_score, indent=2))
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Team Scoring): {e}")

    # # =========================================================
    # # PHASE 2: PROBLEM EVALUATION
    # # =========================================================
    # print("\n" + "="*50)
    # print("üß© PHASE 2: PROBLEM EVALUATION AGENT")
    # print("="*50)
    # problem_scope_data = extract_problem_data(input_data)

    # problem_def = input_data.get("startup_evaluation", {}).get("problem_definition", {})
    
    # # A. Search Validation
    # print("\nüîé Searching for Evidence (Problem Validation)...")
    # if problem_def:
    #     search_output = verify_problem_claims(
    #         problem_statement=problem_def.get("problem_statement", ""),
    #         target_audience=problem_def.get("customer_profile", {}).get("role", "")
    #     )
    #     print("   -> Search Complete.")
    # else:
    #     print("‚ö†Ô∏è No problem definition found.")
    #     search_output = {}

    # # B. Risk Check (Problem Specific)
    # print("\nüìâ Analyzing Problem Risks...")
    # try:
    #     problem_risk_report = loaded_risk_check_with_search(
    #         problem_data=problem_def,
    #         search_results=search_output,
    #         agent_prompt=VALUATION_RISK_PROBLEM_PROMPT_TEMPLATE
    #     )
    #     print("   -> Done.")
    # except Exception as e:
    #     problem_risk_report = f"Error: {e}"

    # # C. Contradiction Check (Problem Specific)
    # print("\nü§ñ Running Problem Contradiction Check...")
    # try:
    #     problem_contradiction_result = contradiction_check(problem_scope_data, agent_prompt=CONTRADICTION_PROBLEM_PROMPT_TEMPLATE)
    #     print("   -> Done.")
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Contradiction): {e}")
    #     problem_contradiction_result = "Contradiction Check Failed."
    
    # # D. Scoring Agent
    # print("\nüèÜ Running Problem Scoring Agent...")
    # try:
    #     problem_data_package = {
    #         "problem_definition": problem_def,
    #         "missing_report": missing_fields_result,
    #         "search_report": search_output,
    #         "risk_report": problem_risk_report,
    #         "contradiction_report": problem_contradiction_result
    #     }
    #     final_problem_score = problem_scoring_agent(problem_data_package)
    #     print(final_problem_score)
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Problem Scoring): {e}")



    # =========================================================
    # PHASE 3: PRODUCT EVALUATION
    # =========================================================
    # print("\n" + "="*50)
    # print("üß© PHASE 3: PRODUCT EVALUATION AGENT")
    # print("="*50)

    # print("‚úÇÔ∏è  Extracting Product-Specific Context...")
    # # This creates a smaller, cleaner JSON just for the Product Agent
    # product_scope_data = extract_product_data(raw_startup_data)

    #  # A. Contradiction Check
    # print("\nü§ñ Running Product Contradiction Check...")
    # try:
    #     product_contradiction_result = contradiction_check(product_scope_data, agent_prompt=CONTRADICTION_PRODUCT_PROMPT_TEMPLATE)
    #     print(product_contradiction_result)
    #     print("   -> Done.")
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Contradiction): {e}")
    #     product_contradiction_result = "Error."
    # ################ will be removed and used from problem evaluation phase ###############

    # # A. Search Validation 
    # print("\nüîé Searching for Evidence (Problem Validation)...")
    # if problem_def:
    #     search_output = verify_problem_claims(
    #         problem_statement=problem_def.get("problem_statement", ""),
    #         target_audience=problem_def.get("customer_profile", {}).get("role", "")
    #     )
    #     print("   -> Search Complete.")
    # else:
    #     print("‚ö†Ô∏è No problem definition found.")
    #     search_output = {}
    # ################ will be removed and used from problem evaluation phase ###############

    #  # A. Risk Check (Product Specific)
    # print("\nüìâ Running Product Risk Check...")
    # try:
    #     product_risk_result = loaded_risk_check_with_search(input_data, search_results=search_output["competitor_search"], agent_prompt=VALUATION_RISK_PRODUCT_PROMPT_TEMPLATE)
    #     print(product_risk_result)
    #     print("   -> Done.")
    # except Exception as e:
    #     print(f"‚ùå Execution Error (Risk): {e}")
    #     product_risk_result = "Error."
    
    
    # url = raw_startup_data.get("company_snapshot", {}).get("website_url", "")
    # print("\nüîç Running Tech Stack Detective...")
    # tech_results = tech_stack_detective(url)
    # print("\n".join([f"{k}: {v}" for k, v in tech_results.items()]))

    # company = raw_startup_data.get("company_snapshot", {}).get("company_name", "The Company")
    # url = raw_startup_data.get("company_snapshot", {}).get("website_url", "")

    # print(f"Analyzing visual identity for {company}...")

    # # Pass the global prompt template into the function
    # analysis_result = analyze_visuals_with_langchain(
    #     company_name=company, 
    #     website_url=url, 
    #     prompt_template=VISUAL_VERIFICATION_PROMPT
    # )

    # print("\n" + "="*40)
    # print("VISION AGENT RESULT:")
    # print("="*40)
    # print(analysis_result)

    # =========================================================
    # 3. FINAL SCORING (The Judge)
    # =========================================================
    # print("\n" + "="*50)
    # print("‚öñÔ∏è  CALCULATING FINAL PRODUCT SCORE...")
    # print("="*50)

    # # A. Pack the data
    # product_data_package = {
    #     "internal_data": product_scope_data,
    #     "contradiction_report": product_contradiction_result,
    #     "risk_report": product_risk_result,
    #     "tech_stack_report": tech_results,    # Pass the dict or str
    #     "visual_analysis_report": analysis_result
    # }

    # # B. Call the function
    # final_score_report = product_scoring_agent(product_data_package)

    # # C. Print Result
    # print(final_score_report)
    
    
    # =========================================================
    # PHASE 4: MARKET EVALUATION
    # =========================================================
    print("\n" + "="*50)
    print("üß© PHASE 4: MARKET EVALUATION AGENT")
    print("="*50)

    print("‚úÇÔ∏è  Extracting Market-Specific Context...")
    # This creates a smaller, cleaner JSON just for the Market Agent
    market_scope_data = extract_market_data(raw_startup_data)
    # print(market_scope_data)
    print("\nüöÄ Calling TAM Tool...")

    beachhead_text = market_scope_data["entry_point"]["beachhead_definition"]
    hq_location = market_scope_data["entry_point"]["location"]

    target_location = hq_location
    if "North America" in beachhead_text:
        target_location = "North America"

    tam_result = tam_sam_verifier_tool(
        beachhead=beachhead_text,
        location=target_location, 
        claimed_size=market_scope_data["entry_point"]["som_size_claim"]
    )

    print(json.dumps(tam_result, indent=2))



    category = market_scope_data["scalability"]["future_category"]
    location = market_scope_data["entry_point"]["location"]

    # # 3. Conditional Execution
    if category and location:
        print(f"\nüì° Running Regulation & Trend Radar...")
        radar_result = regulation_trend_radar_tool(
            category=category,
            location=location
        )
        print(json.dumps(radar_result, indent=2))
    else:
        print("\n Skipping Regulation Radar: Missing 'Category' or 'Location' in data.")

    # A. Contradiction Check
    print("\nü§ñ Running Market Contradiction Check...")
    try:
        market_contradiction_result = contradiction_check(market_scope_data, agent_prompt=CONTRADICTION_MARKET_PROMPT_TEMPLATE)
        print(market_contradiction_result)
        print("   -> Done.")
    except Exception as e:
        print(f"‚ùå Execution Error (Contradiction): {e}")
        market_contradiction_result = "Error."


    product_context = market_scope_data["scalability"]["future_category"]
    competitor_context = market_scope_data["risks"]["current_competitors"] 

    # The Magic Line: Combine them to give the LLM context
    tech_inference = f"Category: {product_context}. Methodology based on: {competitor_context}"

    print(f"üïµÔ∏è  Calling Dependency Detective with context: {tech_inference}...")

    # 3. Call the Function
    result = local_dependency_detective(
        tech_stack=tech_inference,  
        acquisition_channel=market_scope_data["risks"]["acquisition_channel"],
        product_desc=product_context
    )

    print(json.dumps(result, indent=2))


    market_risk_agent_result = market_risk_agent(
        market_inputs=market_scope_data,
        tam_result=tam_result,
        radar_result=radar_result,  
        dep_result=result
    )
    print("\n" + "="*40)
    print("MARKET RISK AGENT RESULT:")
    print("="*40)
    print(market_risk_agent_result)

    market_data_package = {
    "internal_data": extract_market_data(market_scope_data), # The extracted JSON
    "contradiction_report": market_contradiction_result, # Or output from Contradiction Agent
    "tam_report": tam_result,       # Output from TAM Tool
    "radar_report": radar_result,   # Output from Radar Tool
    "dependency_report": result # Output from Dependency Detective
    }

    # Run the Agent
    final_report = market_scoring_agent(market_data_package)
    print(final_report)

    
    # =========================================================
    # FINISH
    # =========================================================
    end_time = time.time()
    execution_time = end_time - start_time
    print("\n" + "="*50)
    print(f"‚úÖ Pipeline finished in {execution_time:.2f} seconds")